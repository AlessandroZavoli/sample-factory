env: doom_battle
run: IMPALA
config:
    # kl_coeff: 0.5  <-- not supported by IMPALA. TODO?
    # vf_share_layers: true  <-- layers between actore and critic are always shared in APPO

    entropy_coeff: 0.003
    train_batch_size: 512
    sample_batch_size: 32
    num_data_loader_buffers: 1
    minibatch_buffer_size: 1
    replay_proportion: 0.0
    replay_buffer_num_slots: 0
    num_sgd_iter: 1

    # lr: 0.00005
    lr_schedule: [ [0, 0.0005], [20000000, 0.000000000001], ]

    num_workers: 18
    num_envs_per_worker: 8
    batch_mode: truncate_episodes
    observation_filter: NoFilter

    num_gpus: 2
    model:
        # lstm_use_prev_action_reward: True  <-- not supported by APPO?

        custom_model: vizdoom_vision_model
        conv_filters: [
            [32, [8, 8], 4],
            [64, [4, 4], 2],
            [64, [3, 3], 2],
            [128, [3, 3], 2],
        ]
        conv_activation: relu
        fcnet_activation: relu  # was tanh

        use_lstm: False
        max_seq_len: 16
        lstm_cell_size: 256

        framestack: False
        grayscale: False
        zero_mean: False